name: Parallel Web Scraping

on:
  workflow_dispatch:
    inputs:
      batch_size:
        description: 'Number of analysts per batch'
        default: '5'
        required: true

jobs:
  setup:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.create-matrix.outputs.matrix }}
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas openpyxl
          
      - name: Create batches
        id: create-matrix
        run: |
          MATRIX=$(python - <<EOF
          import pandas as pd
          import math
          import json
          
          # Read Excel file
          df = pd.read_excel('broker_analyst_2_1.xlsx')
          total_analysts = len(df)
          batch_size = int('${{ github.event.inputs.batch_size }}')
          num_batches = math.ceil(total_analysts / batch_size)
          
          # Create batch ranges
          batches = []
          for i in range(num_batches):
              start = i * batch_size
              end = min((i + 1) * batch_size, total_analysts)
              batches.append(f"{start}-{end}")
          
          # Create matrix output
          matrix = {"batch": batches}
          print(json.dumps(matrix))
          EOF
          )
          echo "matrix=$MATRIX" >> $GITHUB_OUTPUT
        shell: bash

  scrape:
    needs: setup
    runs-on: ubuntu-latest
    strategy:
      matrix: ${{fromJson(needs.setup.outputs.matrix)}}
      fail-fast: false
      max-parallel: 5
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: Install Chrome
        run: |
          sudo apt-get update
          sudo apt-get install -y chromium-browser chromium-chromedriver
          
      - name: Install dependencies
        run: pip install -r requirements.txt
        
      - name: Run scraper
        run: |
          python src/scraper.py --batch ${{ matrix.batch }}
        env:
          PYTHONUNBUFFERED: 1
          
      - name: Upload results
        uses: actions/upload-artifact@v3
        with:
          name: scraping-results-batch-${{ matrix.batch }}
          path: downloads/
          retention-days: 5