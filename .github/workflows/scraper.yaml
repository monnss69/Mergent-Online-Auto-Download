name: Parallel Web Scraping

on:
  workflow_dispatch:
    inputs:
      batch_size:
        description: 'Number of analysts per batch'
        default: '5'
        required: true

jobs:
  setup:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.create-matrix.outputs.matrix }}
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas openpyxl
          
      - name: Create batches
        id: create-matrix
        run: |
          MATRIX=$(python - <<EOF
          import pandas as pd
          import math
          import json
          
          # Read Excel file
          df = pd.read_excel('broker_analyst_2_1.xlsx')
          total_analysts = len(df)
          batch_size = int('${{ github.event.inputs.batch_size }}')
          num_batches = math.ceil(total_analysts / batch_size)
          
          # Create batch ranges
          batches = []
          for i in range(num_batches):
              start = i * batch_size
              end = min((i + 1) * batch_size, total_analysts)
              batches.append(f"{start}-{end}")
          
          # Create matrix output
          matrix = {"batch": batches}
          print(json.dumps(matrix))
          EOF
          )
          echo "matrix=$MATRIX" >> $GITHUB_OUTPUT
        shell: bash

  scrape:
    needs: setup
    runs-on: ubuntu-latest
    strategy:
      matrix: ${{fromJson(needs.setup.outputs.matrix)}}
      fail-fast: false
      max-parallel: 3
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: Setup Chrome and ChromeDriver
        run: |
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable
          # Install ChromeDriver
          LATEST_CHROMEDRIVER="$(curl -s https://googlechromelabs.github.io/chrome-for-testing/LATEST_RELEASE_STABLE)"
          echo "Latest ChromeDriver: ${LATEST_CHROMEDRIVER}"
          wget -q "https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/${LATEST_CHROMEDRIVER}/linux64/chromedriver-linux64.zip"
          unzip chromedriver-linux64.zip
          sudo mv chromedriver-linux64/chromedriver /usr/local/bin/
          sudo chmod +x /usr/local/bin/chromedriver
          google-chrome --version
          chromedriver --version
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: List directory contents
        run: ls -la
          
      - name: Run scraper
        env:
          PYTHONUNBUFFERED: 1
          CHROME_BINARY_PATH: /usr/bin/google-chrome
        run: |
          python src/scraper.py --batch ${{ matrix.batch }}
          
      - name: Upload results
        uses: actions/upload-artifact@v3
        with:
          name: scraping-results-batch-${{ matrix.batch }}
          path: downloads/
          retention-days: 5